{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "### Hands-on : GPT\n",
    "***\n",
    "* We will use the GPT-2 model for NLG/Language Modelling\n",
    "* Try seeding various sentence fragments and see what it comes up with\n",
    "\n",
    "* Was OpenAI justified in staged release ?\n",
    "* Has our new overlords reached a stage where they can fool us ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch ver : 1.4.0\n",
      "TorchText Ver : 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch ver :\",torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#\n",
    "# pip install https://github.com/pytorch/text/archive/master.zip\n",
    "import torchtext\n",
    "print(F'TorchText Ver : {torchtext.__version__}')\n",
    "from torchtext import data\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchsummary import summary\n",
    "# pip install torchsummary\n",
    "#\n",
    "import numpy as np\n",
    "import datetime # use datetime.datetime.now() prints in a nice hh:mm:ss.nn forma\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda : F\n"
     ]
    }
   ],
   "source": [
    "is_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print('Cuda : {:.1s}'.format(str(is_cuda)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0221 20:58:15.685184 4640626112 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "I0221 20:58:19.385239 4640626112 file_utils.py:57] TensorFlow version 2.0.0-beta1 available.\n"
     ]
    }
   ],
   "source": [
    "# Huggingface Transformers\n",
    "# pip install transformers\n",
    "# Might need rust compiler\n",
    "# curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n",
    "# need Cargo's bin directory ($HOME/.cargo/bin) in your PATH environment variable\n",
    "import transformers\n",
    "# The GPT2 Model transformer with a language modeling head on top \n",
    "#   (linear layer with weights tied to the input embeddings).\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0221 20:58:22.202440 4640626112 tokenization_utils.py:484] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /Users/ksankar/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I0221 20:58:22.203521 4640626112 tokenization_utils.py:484] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /Users/ksankar/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0221 20:58:22.759586 4640626112 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /Users/ksankar/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
      "I0221 20:58:22.761580 4640626112 configuration_utils.py:290] Model config GPT2Config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "I0221 20:58:23.139919 4640626112 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /Users/ksankar/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model config GPT2Config {\n",
    "  \"architectures\": [\n",
    "    \"GPT2LMHeadModel\"\n",
    "  ],\n",
    "  \"attn_pdrop\": 0.1,\n",
    "  \"bos_token_id\": 0,\n",
    "  \"do_sample\": false,\n",
    "  \"embd_pdrop\": 0.1,\n",
    "  \"eos_token_ids\": 0,\n",
    "  \"finetuning_task\": null,\n",
    "  \"id2label\": {\n",
    "    \"0\": \"LABEL_0\",\n",
    "    \"1\": \"LABEL_1\"\n",
    "  },\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"is_decoder\": false,\n",
    "  \"label2id\": {\n",
    "    \"LABEL_0\": 0,\n",
    "    \"LABEL_1\": 1\n",
    "  },\n",
    "  \"layer_norm_epsilon\": 1e-05,\n",
    "  \"length_penalty\": 1.0,\n",
    "  \"max_length\": 20,\n",
    "  \"model_type\": \"gpt2\",\n",
    "  \"n_ctx\": 1024,\n",
    "  \"n_embd\": 768,\n",
    "  \"n_head\": 12,\n",
    "  \"n_layer\": 12,\n",
    "  \"n_positions\": 1024,\n",
    "  \"num_beams\": 1,\n",
    "  \"num_labels\": 2,\n",
    "  \"num_return_sequences\": 1,\n",
    "  \"output_attentions\": false,\n",
    "  \"output_hidden_states\": false,\n",
    "  \"output_past\": true,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"pruned_heads\": {},\n",
    "  \"repetition_penalty\": 1.0,\n",
    "  \"resid_pdrop\": 0.1,\n",
    "  \"summary_activation\": null,\n",
    "  \"summary_first_dropout\": 0.1,\n",
    "  \"summary_proj_to_labels\": true,\n",
    "  \"summary_type\": \"cls_index\",\n",
    "  \"summary_use_proj\": true,\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_k\": 50,\n",
    "  \"top_p\": 1.0,\n",
    "  \"torchscript\": false,\n",
    "  \"use_bfloat16\": false,\n",
    "  \"vocab_size\": 50257\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "['We', 'Ġlike', 'ĠUnic', 'orns', 'Ġbecause', 'Ġthey']\n",
      "['Here', 'Ġis', 'Ġthe', 'Ġsentence', 'ĠI', 'Ġwant', 'Ġembed', 'd', 'ings', 'Ġfor', '.']\n"
     ]
    }
   ],
   "source": [
    "print(gpt2_tokenizer.vocab_size)\n",
    "input_text = gpt2_tokenizer.encode(\"We like Unicorns because they\")\n",
    "print(gpt2_tokenizer.convert_ids_to_tokens(input_text))\n",
    "input_text = gpt2_tokenizer.encode(\"Here is the sentence I want embeddings for.\")\n",
    "print(gpt2_tokenizer.convert_ids_to_tokens(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gpt2_sentence_prediction(text,n=50):\n",
    "    input_text = gpt2_tokenizer.encode(text)\n",
    "    input,past = torch.tensor([input_text]),None\n",
    "    for _ in range(n):#25):\n",
    "        logits,past = gpt2_model(input,past=past)\n",
    "        input = torch.multinomial(F.softmax(logits[:,-1]),1)\n",
    "        input_text.append(input.item())\n",
    "    return gpt2_tokenizer.decode(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We like Unicorns because they have fast baneling fury, hard pressure and ward.\n",
      "\n",
      "\n",
      "Statistics\n",
      "\n",
      "\n",
      "Level 1: 2368 (78 Rank)\n",
      "\n",
      "\n",
      "Experiment #13: Join Alliance\n",
      "\n",
      "by Gorgeius (nice hack)\n",
      "\n",
      "\n",
      "Level 1: 250 (\n"
     ]
    }
   ],
   "source": [
    "in_text = \"We like Unicorns because they\"\n",
    "out = run_gpt2_sentence_prediction(in_text)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output from a run on 2/21/20 7:00 PM\n",
    "\n",
    "`We like Unicorns because they are committed to building the most progressive platform so no major issues are going to come up again.\n",
    "\n",
    "The race against Unicorns has become a proving ground for champion performance in eSports, and the local leagues have found greater strength.\n",
    "\n",
    "Leaguepedia`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "After swimming alone in a lake for just under a week north of Bolivia's capital Puebla and chowing down face-to-face with some large wilds (save for some small more common frachy-huana like chillalone) and other lifeform (such as exotic jellyfish with crocodilian features) among the nearly 2.6 million other natural task animals on Earth from animal to animal, Chi- Chi also found that a number of minnows and some domesticated\n"
     ]
    }
   ],
   "source": [
    "in_text = \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously \\\n",
    "unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the \\\n",
    "unicorns spoke perfect English.\"\n",
    "out = run_gpt2_sentence_prediction(in_text,100)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise,Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back.The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying toturn itself over,but it can’t, not without your help. But you’re not helping. Why is that? You see to it that it is not starved‼This is why‬this is why. Because when you think about․they see your mouth,‼they think‼she could reach․this way․and‼how‼but‼she‼you‬can› pull․you out‼very quickly‼because she falters in the hot sun and›it''s**you‬ere leaking oil.Wolf - If you lean against her while resting and gaze at her palms with her not intending‼to–she‼is‹resting on her knees,‼but if she doesn't take milk orcheese?›Does she? You don´t know?Wife‼proud‼looking at me with commanding eyes.Daughter standing facing me:‼how about‼working‼daddy on her knees,Anna catches her breath:Putting\n"
     ]
    }
   ],
   "source": [
    "in_text = \"You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise,\\\n",
    "Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back.\\\n",
    "The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to\\\n",
    "turn itself over,but it can’t, not without your help. But you’re not helping. Why is that?\"\n",
    "out = run_gpt2_sentence_prediction(in_text,200)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework:\n",
    "* This is an open topic to explore\n",
    "* Try your own text and see how the GPT responds\n",
    "* Try longer sentences - input and output - I have capped the output at 200 words\n",
    "* Do you get better longer response with an input with longer sentences ?\n",
    "* How many times do you have to do before getting an output that is interesting ?\n",
    "* Does the model give coherent output at the first try ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_text = \"\"\n",
    "# output_length = 200\n",
    "# out = run_gpt2_sentence_prediction(in_text,output_length)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can even write a whole book with the help from transformer [here](https://transformer.huggingface.co/)\n",
    "![](Write-with-Transformer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## _That's All Folks !_\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP area\n",
    "### To experiment with different things "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* summary() doesn't work well\n",
    "* you can print(model) to get an idea about the layers\n",
    "* The model_describe() below works reasonably, but the total parameters doesn't look correct\n",
    "* Let me know if you were able to get this to work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(gpt2_model,[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_describe(model):\n",
    "    print(\"model_summary\")\n",
    "    print()\n",
    "    print(F'Layer_name {\"\":30s} Size {\"\":25s} Number of Parameters')\n",
    "    print(\"=\"*100)\n",
    "    total_params = 0\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(F'Layer {param_tensor:35s} {str(model.state_dict()[param_tensor].size()):30s} '\n",
    "              F'elements : {torch.numel(model.state_dict()[param_tensor]):,}')\n",
    "        total_params += torch.numel(model.state_dict()[param_tensor])\n",
    "    # total_params = sum(p.numel() for p in model.parameters()) # sum number of elements\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Total Params:{total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_summary\n",
      "\n",
      "Layer_name                                Size                           Number of Parameters\n",
      "====================================================================================================\n",
      "Layer transformer.wte.weight              torch.Size([50257, 768])       elements : 38,597,376\n",
      "Layer transformer.wpe.weight              torch.Size([1024, 768])        elements : 786,432\n",
      "Layer transformer.h.0.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.0.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.0.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.0.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.0.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.0.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.0.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.0.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.0.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.0.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.0.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.0.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.0.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.1.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.1.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.1.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.1.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.1.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.1.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.1.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.1.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.1.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.1.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.1.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.1.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.1.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.2.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.2.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.2.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.2.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.2.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.2.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.2.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.2.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.2.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.2.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.2.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.2.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.2.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.3.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.3.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.3.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.3.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.3.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.3.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.3.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.3.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.3.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.3.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.3.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.3.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.3.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.4.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.4.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.4.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.4.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.4.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.4.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.4.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.4.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.4.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.4.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.4.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.4.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.4.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.5.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.5.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.5.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.5.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.5.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.5.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.5.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.5.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.5.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.5.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.5.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.5.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.5.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.6.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.6.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.6.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.6.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.6.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.6.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.6.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.6.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.6.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.6.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.6.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.6.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.6.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.7.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.7.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.7.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.7.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.7.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.7.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.7.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.7.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.7.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.7.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.7.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.7.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.7.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.8.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.8.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.8.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.8.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.8.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.8.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.8.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.8.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.8.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.8.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.8.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.8.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.8.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.9.ln_1.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.9.ln_1.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.9.attn.bias           torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.9.attn.c_attn.weight  torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.9.attn.c_attn.bias    torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.9.attn.c_proj.weight  torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.9.attn.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.9.ln_2.weight         torch.Size([768])              elements : 768\n",
      "Layer transformer.h.9.ln_2.bias           torch.Size([768])              elements : 768\n",
      "Layer transformer.h.9.mlp.c_fc.weight     torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.9.mlp.c_fc.bias       torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.9.mlp.c_proj.weight   torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.9.mlp.c_proj.bias     torch.Size([768])              elements : 768\n",
      "Layer transformer.h.10.ln_1.weight        torch.Size([768])              elements : 768\n",
      "Layer transformer.h.10.ln_1.bias          torch.Size([768])              elements : 768\n",
      "Layer transformer.h.10.attn.bias          torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.10.attn.c_attn.weight torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.10.attn.c_attn.bias   torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.10.attn.c_proj.weight torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.10.attn.c_proj.bias   torch.Size([768])              elements : 768\n",
      "Layer transformer.h.10.ln_2.weight        torch.Size([768])              elements : 768\n",
      "Layer transformer.h.10.ln_2.bias          torch.Size([768])              elements : 768\n",
      "Layer transformer.h.10.mlp.c_fc.weight    torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.10.mlp.c_fc.bias      torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.10.mlp.c_proj.weight  torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.10.mlp.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.h.11.ln_1.weight        torch.Size([768])              elements : 768\n",
      "Layer transformer.h.11.ln_1.bias          torch.Size([768])              elements : 768\n",
      "Layer transformer.h.11.attn.bias          torch.Size([1, 1, 1024, 1024]) elements : 1,048,576\n",
      "Layer transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])        elements : 1,769,472\n",
      "Layer transformer.h.11.attn.c_attn.bias   torch.Size([2304])             elements : 2,304\n",
      "Layer transformer.h.11.attn.c_proj.weight torch.Size([768, 768])         elements : 589,824\n",
      "Layer transformer.h.11.attn.c_proj.bias   torch.Size([768])              elements : 768\n",
      "Layer transformer.h.11.ln_2.weight        torch.Size([768])              elements : 768\n",
      "Layer transformer.h.11.ln_2.bias          torch.Size([768])              elements : 768\n",
      "Layer transformer.h.11.mlp.c_fc.weight    torch.Size([768, 3072])        elements : 2,359,296\n",
      "Layer transformer.h.11.mlp.c_fc.bias      torch.Size([3072])             elements : 3,072\n",
      "Layer transformer.h.11.mlp.c_proj.weight  torch.Size([3072, 768])        elements : 2,359,296\n",
      "Layer transformer.h.11.mlp.c_proj.bias    torch.Size([768])              elements : 768\n",
      "Layer transformer.ln_f.weight             torch.Size([768])              elements : 768\n",
      "Layer transformer.ln_f.bias               torch.Size([768])              elements : 768\n",
      "Layer lm_head.weight                      torch.Size([50257, 768])       elements : 38,597,376\n",
      "====================================================================================================\n",
      "Total Params:175,620,096\n"
     ]
    }
   ],
   "source": [
    "model_describe(gpt2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gpt2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_summary\n",
      "\n",
      "Layer_name\t\t\t\t\t\t\tNumber of Parameters\n",
      "====================================================================================================\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\t\t\t39383808\n",
      "\n",
      "Linear(in_features=768, out_features=50257, bias=False)\t\t\t1536\n",
      "====================================================================================================\n",
      "Total Params:39385344\n"
     ]
    }
   ],
   "source": [
    "def model_summary(model): # This calculates wrong, may be it is correct - need to check\n",
    "  print(\"model_summary\")\n",
    "  print()\n",
    "  print(\"Layer_name\"+\"\\t\"*7+\"Number of Parameters\")\n",
    "  print(\"=\"*100)\n",
    "  model_parameters = [layer for layer in model.parameters() if layer.requires_grad]\n",
    "  layer_name = [child for child in model.children()]\n",
    "  j = 0\n",
    "  total_params = 0\n",
    "  print(\"\\t\"*10)\n",
    "  for i in layer_name:\n",
    "    print()\n",
    "    param = 0\n",
    "    try:\n",
    "      bias = (i.bias is not None)\n",
    "    except:\n",
    "      bias = False  \n",
    "    if not bias:\n",
    "      param =model_parameters[j].numel()+model_parameters[j+1].numel()\n",
    "      j = j+2\n",
    "    else:\n",
    "      param =model_parameters[j].numel()\n",
    "      j = j+1\n",
    "    print(str(i)+\"\\t\"*3+str(param))\n",
    "    total_params+=param\n",
    "  print(\"=\"*100)\n",
    "  print(f\"Total Params:{total_params}\")       \n",
    "\n",
    "model_summary(gpt2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 Playground\n",
    "# https://github.com/ilopezfr/gpt-2\n",
    "# Colab Playground \n",
    "# Check out https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy code for testing elapsed time. It prints hh:mm:ss.nnn correctly. time.time() prints the total seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed - 0:02:25.006721\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "start_time = datetime.datetime.now()\n",
    "time.sleep(145)\n",
    "print(F'Elapsed - {datetime.datetime.now() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
